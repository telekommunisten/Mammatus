
To add a tracker to a Mammatus Cloud you simply add an NS records to your DNS zone
and delegate a subdomain to the tracker's IP address.

I.e.  
    - mammacloud.example.com IN NS mamma1.mydomain.com 
    - mammacloud.example.com IN NS mamma2.mydomain.com 
    - mammacloud.example.com IN NS mamma3.mydomain.com
    - Etc...

Because this is a NS record, the tracker itself will be responsible for
resolving it's own ip address. This means two cool things: 1) it will only
respond if it is actually up and running. 2) all existing clients will already
try the next NS record if it does not respond. Super.

Tracker data is stored in redis, so they all have the same data.

i.e.

*.tracker.mammacloud.example.com will allways resolve to a working tracker
because the dns server that recieves the request is the tracker and will point
to itself. keeping ttl extremely short will minimize the time that unavailable
tracker IPs are cached, and applications can rerequest if they want by using
n+1.tracker.mamacloud.example.com type requests.

Storage nodes are collected in groups, each group has a A records in your zone.

    - storage.example.com IN A 111.111.111.111
    - storage.example.com IN A 111.111.111.112 
    - storage.example.com IN A 111.111.111.113

each of these are simple webdav servers, since webdav servers typically
support vhosts, each node can even part of many groups.

you connect a storage group to a tracker by adding a TXT record, i.e.

_storage.mammacloud.example.com IN TXT "group=storage.mydomain.com"

you also specify a replication plan for a group by adding TXT records, i.e.

_replicate.storage.example.com IN TXT "pull:111.111.111 push:111.111.112
push:111.111.3"

or

_replicate.storage.example.com IN TXT "pull:all push:2"

something like that anyway.

The Mammatus tracker serves as a proxy for all uploads, it does the following:

- stores each chunk of the upload and the list of chunks in redis

This way recovery is possible even if the tracker itself goes down during
upload, although the client will need to have support for this.

- once upload is complete, it creates a SHA1 hexdigest of the file, 

- pushes to the storage nodes according to the replication policy using the
  hexdigest as the filename

Like git, using the hexdigest as the filename means that if the same file is
uploaded twice, it's treated as one file within the storage group.

It will also provide json/http progress data given an uploadid like the current
demo

Meta data is provided via the Tracker's DNS server:

If an upload id is provided by the application, it also adds a cname to the
file url, i.e. 

uploadid.upload.mammacloud.example.com in CNAME
"hexdigest.files.mammacloud.example.com"

And TXT records for upload specific meta data, i.e.

uploadid.upload.mammacloud.example.com IN TXT "filename=something.wzb"

also, the hexdigest will be made available:

_hexdigest.uploadid.mamacloud.example.con in TXT "HEXDIGEST..."


- an cname for each file in the format hexdigest.files.mammacloud.example.com

TXT records for the file containing other metadata, i.e:

hexdigest.files.mammacloud.example.com IN TXT "contenttype=bin/something"
etc..

Also a direct A record storage nodes which have the file can optionally be made
available:

hexdigest.storage.example.com IN A 111.111.111.111
hexdigest.storage.example.com IN A 111.111.111.112

now any file can be retrieved using an http get to the url
http://hexdigest.files.mammacloud.example.com via the tracker

or directly from a storage node using the url
http://hexdigest.storage.example.com

Get requests can have two modes, pessimistic and optimistic.

When the tracker receives the get request, it looks up a storage node and
either (in pessimistic mode) proxies the data, checking the hexdigest to detect
corruption, or (in optimistic mode) redirects the request to a storage node.

In optimistic mode the application can also look up the storage node itself
with a dns request, and get the data directly.

While this system will work with any http client, it does have a failure
condition where the tracker (or storage node in an optimistic get) goes down
during a transfer, however the application can still recover in these
situations.

Also, a "mammafuse" module can be written to allow mounting a mammacloud in a
filesystem, this mount can then also be exported via webdav or samba to provide
desktop integrated access.

Let me know what you think. Does this make sense?

Cheers.






